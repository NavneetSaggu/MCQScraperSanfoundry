{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\n#this is for loading pages and shit\nimport bs4\nimport requests\nimport re","execution_count":399,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def geturls(file):\n    line = file.read().replace(\"\\n\", \" \")\n    file.close()\n    start = [i for i in range(len(line)) if line.startswith(\"https\", i)]\n    end = []\n    for index in start:\n        i = index\n        while line[i] != '\"':\n            i = i+1\n        end.append(i)\n    sitelist = []\n    for (s,e) in zip(start,end):\n        sitelist.append(line[s:e])\n    return sitelist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getpages(sitelist):\n    pages = []\n    failed_pages = []\n    \n    for url in sitelist:\n        webpage = requests.get(url)\n        statcode = str(webpage.status_code)\n        # status code starting with a 2 generally indicates success,\n        # and a code starting with a 4 or a 5 indicates an error.\n        # page.content\n        soup = bs4.BeautifulSoup(webpage.content,'html.parser')\n        page = str(soup)\n        \n        readstart = 0\n        readend = 0\n        for i in range(len(page)):\n            if page.startswith(\".entry-header\", i):\n                readstart = i\n            if page.startswith(\"Explanation:\", i):\n                readend = i\n        while (not page.startswith(\"</p>\", readstart)) and readend < len(page): readstart = readstart + 1\n        while (not page.startswith(\"</p>\", readend)) and readend < len(page): readend = readend + 1\n        page = page[readstart:readend]\n        \n        if readstart == 0 or statcode.startswith('4') or statcode.startswith('5'):\n            failed_pages.append(url)\n        else:\n            pages.append(page)\n    return (pages, failed_pages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getdirtyquestions(pages):\n    dirtyquestions = []\n    \n    for page in pages:\n        page = page.replace(\"<br/>\",\" \")\n        qno = 1\n        for i in range(len(page)):\n            if page.startswith(\"<p>\"+str(qno)+\".\", i):\n                qno = qno+1\n                j = i\n                while (not page.startswith(\"Explanation:\", j)) and j < len(page): j = j + 1\n                while (not page.startswith(\"</div>\", j)) and j < len(page): j = j + 1\n                dirtyquestions.append(page[i+3:j])\n    return dirtyquestions","execution_count":336,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getcleanquestions(dirtyquestions):\n    cleanquestions = []\n    for q in dirtyquestions:\n        for i in range(len(q)): \n            if q.startswith(\"<span\", i): break\n        for j in range(len(q)): \n            if q.startswith(\"Answer:\", j): break\n        cleanquestions.append(q[0:i] + q[j:])\n    return cleanquestions\n            ","execution_count":366,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(\"/kaggle/input\")\nfile = open(\"SANCRALWER.txt\")\nsitelist = geturls(file)\n\n# one webpage had no questions\nsitelist = sitelist[0:95]\n\n# fetching the relevant parts of each webpage\n(pages, failed_pages) = getpages(sitelist)\nprint(pages[0])","execution_count":414,"outputs":[{"output_type":"stream","text":"</p>\n<p>1. IBM and ________ have announced a major initiative to use Hadoop to support university courses in distributed computer programming.<br/>\na) Google Latitude<br/>\nb) Android (operating system)<br/>\nc) Google Variations<br/>\nd) Google<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2badb\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2badb\">Answer: d<br/>\nExplanation: Google and IBM Announce University Initiative to Address Internet-Scale.</div>\n<div class=\"mobile-incontent-ads\">\n<div style=\"font-size:13px; text-align: center;\">advertisement</div>\n<div class=\"_ap_apex_ad\" id=\"ba924445-0f94-4f60-acc3-655f343484d9\">\n<script>\n\t    var adpushup = adpushup || {};\n\t    adpushup.que = adpushup.que || [];\n\t    adpushup.que.push(function() {\n\t\tadpushup.triggerAd(\"ba924445-0f94-4f60-acc3-655f343484d9\");\n\t    });\n\t</script>\n</div>\n</div>\n<p>2. Point out the correct statement.<br/>\na) Hadoop is an ideal environment for extracting and transforming small volumes of data<br/>\nb) Hadoop stores data in HDFS and supports data compression/decompression<br/>\nc) The Giraph framework is less  useful than a MapReduce job to solve graph and machine learning<br/>\nd) None of the mentioned<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb00\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb00\">Answer: b<br/>\nExplanation: Data compression can be achieved using compression algorithms like bzip2, gzip, LZO, etc. Different algorithms can be used in different scenarios based on their capabilities.</div> </p>\n<p>3. What license is Hadoop distributed under?<br/>\na) Apache License 2.0<br/>\nb) Mozilla Public License<br/>\nc) Shareware<br/>\nd) Commercial<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb10\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb10\">Answer: a<br/>\nExplanation: Hadoop is Open Source, released under Apache 2 license.</div> </p>\n<p>4. Sun also has the Hadoop Live CD ________ project, which allows running a fully functional Hadoop cluster using a live CD.<br/>\na) OpenOffice.org<br/>\nb) OpenSolaris<br/>\nc) GNU<br/>\nd) Linux<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb1d\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb1d\">Answer: b<br/>\nExplanation: The OpenSolaris Hadoop LiveCD project built a bootable CD-ROM image. </div> </p>\n<p>5. Which of the following genres does Hadoop produce?<br/>\na) Distributed file system<br/>\nb) JAX-RS<br/>\nc) Java Message Service<br/>\nd) Relational Database Management System<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb29\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb29\">Answer: a<br/>\nExplanation: The Hadoop Distributed File System (HDFS) is designed to store very large data sets reliably, and to stream those data sets at high bandwidth to the user.</div> </p>\n<div class=\"mobile-incontent-ads\">\n<div style=\"font-size:13px; text-align: center;\">advertisement</div>\n<div class=\"_ap_apex_ad\" id=\"ba924445-0f94-4f60-acc3-655f343484d9\">\n<script>\n\t    var adpushup = adpushup || {};\n\t    adpushup.que = adpushup.que || [];\n\t    adpushup.que.push(function() {\n\t\tadpushup.triggerAd(\"ba924445-0f94-4f60-acc3-655f343484d9\");\n\t    });\n\t</script>\n</div>\n</div>\n<p>6. What was Hadoop written in?<br/>\na) Java (software platform)<br/>\nb) Perl<br/>\nc) Java (programming language)<br/>\nd) Lua (programming language)<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb33\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb33\">Answer: c<br/>\nExplanation: The Hadoop framework itself is mostly written in the Java programming language, with some native code in C and command-line utilities written as shell-scripts.</div> </p>\n<p>7. Which of the following platforms does Hadoop run on?<br/>\na) Bare metal<br/>\nb) Debian<br/>\nc) Cross-platform<br/>\nd) Unix-like<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb3e\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb3e\">Answer: c<br/>\nExplanation: Hadoop has support for cross-platform operating system.</div> </p>\n<p>8. Hadoop achieves reliability by replicating the data across multiple hosts and hence does not require ________ storage on hosts.<br/>\na) RAID<br/>\nb) Standard RAID levels<br/>\nc) ZFS<br/>\nd) Operating system<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb48\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb48\">Answer: a<br/>\nExplanation: With the default replication value, 3, data is stored on three nodes: two on the same rack, and one on a different rack.</div> </p>\n<p>9. Above the file systems comes the ________ engine, which consists of one Job Tracker, to which client applications submit MapReduce jobs.<br/>\na) MapReduce<br/>\nb) Google<br/>\nc) Functional programming<br/>\nd) Facebook<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb52\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb52\">Answer: a<br/>\nExplanation: MapReduce engine uses to distribute work around a cluster.</div> </p>\n<p>10. The Hadoop list includes the HBase database, the Apache Mahout ________ system, and matrix operations.<br/>\na) Machine learning<br/>\nb) Pattern recognition<br/>\nc) Statistical classification<br/>\nd) Artificial intelligence<br/>\n<span class=\"collapseomatic\" id=\"id5ede214b2bb5d\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2bb5d\">Answer: a<br/>\nExplanation: The Apache Mahout projectâ€™s goal is to build a scalable machine learning tool.</div> \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting questions from relevant sections of HTML webpage\ndirtyquestions = getdirtyquestions(pages)\nprint(dirtyquestions[0])","execution_count":415,"outputs":[{"output_type":"stream","text":"1. IBM and ________ have announced a major initiative to use Hadoop to support university courses in distributed computer programming. \na) Google Latitude \nb) Android (operating system) \nc) Google Variations \nd) Google \n<span class=\"collapseomatic\" id=\"id5ede214b2badb\" tabindex=\"\" title=\"View Answer\">View Answer</span><div class=\"collapseomatic_content\" id=\"target-id5ede214b2badb\">Answer: d \nExplanation: Google and IBM Announce University Initiative to Address Internet-Scale.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this was for testing whether standard format was being followed\nseparator = \" \"\ntestpages = separator.join(pages)\nprint(testpages.count(\"Answer:\"))","execution_count":411,"outputs":[{"output_type":"stream","text":"958\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"countspan = 0\ncountnospan = 0\nindexwithoutspan = 0\nfor qi in range(len(dirtyquestions)):\n    if dirtyquestions[qi].count(\"<span\") == 0:\n        countnospan = countnospan + 1\n        indexwithoutspan = qi\n    else:\n        countspan = countspan + 1\nprint(\"Span : \" + str(countspan) + \"\\nNo Span : \" + str(countnospan) + \"\\nIndex Without Span : \" + str(indexwithoutspan))\nprint(\"\\nQuestion without span : \\n\" + dirtyquestions[indexwithoutspan])\n\n# there were three questions deviating from the standard HTML format, which were treated seperately as no span, owing to their missing <span> tags\nnospanquestion = dirtyquestions[375]\n\n# removing no span question from dirtyquestions\ndirtyquestions = dirtyquestions[0:375] + dirtyquestions[376:956]","execution_count":380,"outputs":[{"output_type":"stream","text":"Span : 955\nNo Span : 1\nIndex Without Span : 375\n\nQuestion without span : \n8. Which is the additional command line option is available in Hive 0.10.0? \na) â€“database &lt;dbname&gt; \nb) â€“db &lt;dbname&gt; \nc) â€“dbase &lt;&lt;dbname&gt;\nd) All of the mentioned\n[expand title=\"View Answer\"]Answer: a\nExplanation: Database is specified which is to be used.[/expand] \n\n9. The CLI when invoked without the -i option will attempt to load $HIVE_HOME/bin/.hiverc and $HOME/.hiverc as _______ files.\na) processing\nb) termination\nc) initialization\nd) none of the mentioned\n[expand title=\"View Answer\"]Answer: c \nExplanation: Hiverc file is loaded as per options selected.[/expand] \n\n10. When $HIVE_HOME/bin/hive is run without either the -e or -f option, it enters _______ mode.\na) Batch\nb) Interactive shell\nc) Multiple\nd) None of the mentioned\n[expand title=\"View Answer\"]Answer: b\nExplanation: Use \";\" (semicolon) to terminate commands for multiple options available.[/expand] \n\n<strong>Sanfoundry Global Education &amp; Learning Series â€“ Hadoop.</strong>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cleaning no span question manually\nnospanquestion = \"8. Which is the additional command line option is available in Hive 0.10.0? \\na) â€“database &lt;dbname&gt; \\nb) â€“db &lt;dbname&gt; \\nc) â€“dbase &lt;&lt;dbname&gt;\\nd) All of the mentioned\\nAnswer: a\\nExplanation: Database is specified which is to be used.\\n\\n9. The CLI when invoked without the -i option will attempt to load $HIVE_HOME/bin/.hiverc and $HOME/.hiverc as _______ files.\\na) processing\\nb) termination\\nc) initialization\\nd) none of the mentioned\\nAnswer: c \\nExplanation: Hiverc file is loaded as per options selected.\\n\\n10. When $HIVE_HOME/bin/hive is run without either the -e or -f option, it enters _______ mode.\\na) Batch\\nb) Interactive shell\\nc) Multiple\\nd) None of the mentioned\\nAnswer: b\\nExplanation: Use \\\";\\\" (semicolon) to terminate commands for multiple options available.\"","execution_count":412,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cleaning span questions\ncleanquestions = getcleanquestions(dirtyquestions)\nprint(cleanquestions[0])","execution_count":416,"outputs":[{"output_type":"stream","text":"1. IBM and ________ have announced a major initiative to use Hadoop to support university courses in distributed computer programming. \na) Google Latitude \nb) Android (operating system) \nc) Google Variations \nd) Google \nAnswer: d \nExplanation: Google and IBM Announce University Initiative to Address Internet-Scale.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# putting everything together\nfinal = \"\\n\\n\".join(cleanquestions)\nfinal = final + \"\\n\\n\" + nospanquestion","execution_count":418,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(\"/kaggle/working\")\nwith open(\"test.txt\", \"w\") as f:\n    f.write(final)","execution_count":419,"outputs":[{"output_type":"error","ename":"OSError","evalue":"[Errno 30] Read-only file system: 'test.txt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-419-2005f546032f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: 'test.txt'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}